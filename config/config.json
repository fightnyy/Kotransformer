{
    "batch_size": 4,
    "n_enc_vocab": 8007,
    "n_dec_vocab": 8007,
    "n_enc_seq": 128,
    "n_dec_seq": 128,
    "n_layer": 3,
    "d_hidn": 128,
    "i_pad": 0,
    "d_ff": 512,
    "n_head": 4,
    "d_head": 32,
    "dropout": 0.1,
    "layer_norm_epsilon": 1e-12,
    "device": "None",
    "n_output": 2,
    "weight_decay": 0,
    "learning_rate": 5e-5,
    "adam_epsilon": 1e-8,
    "warmup_steps":0,
    "n_epoch":10

}
