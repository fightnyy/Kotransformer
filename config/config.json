{
    "batch_size": 128,
    "n_enc_vocab": 8007,
    "n_dec_vocab": 8007,
    "n_enc_seq": 128,
    "n_dec_seq": 128,
    "n_layer": 6,
    "d_hidn": 512,
    "i_pad": 0,
    "d_ff": 1024,
    "n_head": 8,
    "d_head": 64,
    "dropout": 0.1,
    "layer_norm_epsilon": 1e-12,
    "device": "None",
    "n_output": 2,
    "weight_decay": 0,
    "learning_rate": 5e-5,
    "adam_epsilon": 1e-8,
    "warmup_steps":0,
    "n_epoch":10

}
